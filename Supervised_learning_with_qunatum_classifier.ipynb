{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sublime-filter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 s, sys: 1.43 s, total: 4.41 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gzip\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organized-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 199 ms, sys: 14.3 ms, total: 213 ms\n",
      "Wall time: 211 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Useful additional packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.version.version\n",
    "np.seterr(all=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 259 ms, total: 1.38 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, execute\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.quantum_info import state_fidelity, OneQubitEulerDecomposer\n",
    "from qiskit import  Aer, transpile, IBMQ, assemble\n",
    "from qiskit.circuit.library import CHGate\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit.aqua.operators import PrimitiveOp, CircuitStateFn\n",
    "from qiskit.aqua.operators.primitive_ops import MatrixOp\n",
    "from qiskit.aqua.operators.converters import CircuitSampler\n",
    "from qiskit.aqua.operators.expectations import MatrixExpectation\n",
    "from qiskit.aqua.operators.list_ops import ComposedOp\n",
    "from qiskit.aqua.operators import ListOp\n",
    "from qiskit.aqua.components.initial_states import Zero\n",
    "import qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understood-machinery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 126 ms, sys: 16.7 ms, total: 143 ms\n",
      "Wall time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from geomstats.geometry.special_orthogonal import SpecialOrthogonal\n",
    "from geomstats.learning.pca import TangentPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vulnerable-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__init__.discover_credentials:INFO:2021-05-04 23:24:20,601: Using credentials from qiskitrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 120 µs, total: 136 ms\n",
      "Wall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "provider = IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfied-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prescription-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.55 ms, sys: 1.24 ms, total: 4.79 ms\n",
      "Wall time: 3.47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print(Aer.backends())\n",
    "simulator = Aer.get_backend(\"statevector_simulator\") # unable to run on current quantum architechture, due to circuit incompatability\n",
    "my_sampler = CircuitSampler(backend=simulator, attach_results=True, param_qobj=False)\n",
    "my_expectation = MatrixExpectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desirable-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 7.63 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# EMNIST decoder\n",
    "\n",
    "decoder = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.15 ms, sys: 1.79 ms, total: 6.94 ms\n",
      "Wall time: 13.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "images_raw = gzip.open(\"data/MNIST/MNIST_GZ/train-images-idx3-ubyte.gz\", \"r\")\n",
    "labels_raw = gzip.open(\"data/MNIST/MNIST_GZ/train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "\n",
    "image_size = 28\n",
    "num_images = 8192 # how many images total\n",
    "\n",
    "images_raw.read(16) # reads the data type\n",
    "labels_raw.read(8) # reads the data type\n",
    "\n",
    "def get_data(images, labels):\n",
    "    buf_images = images.read(image_size * image_size * num_images)\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(num_images, image_size, image_size, 1)\n",
    "    \n",
    "    buf_labels = labels.read(num_images)\n",
    "    labels = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int32)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intense-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_num_cls(data):\n",
    "    labels = np.array(data[1])\n",
    "    one_hot_labels = to_categorical(labels)\n",
    "    \n",
    "    return one_hot_labels.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hired-pakistan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  10\n",
      "(6144, 28, 28, 1)\n",
      "(6144,)\n",
      "(2048, 28, 28, 1)\n",
      "(2048,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print images\n",
    "data = get_data(images_raw, labels_raw)\n",
    "N = get_num_cls(data)\n",
    "print(\"Number of classes = \", N)\n",
    "data_split = int(data[0].shape[0] * 0.75)\n",
    "images, test_images = data[0][0: data_split], data[0][data_split:]\n",
    "labels, test_labels = data[1][0: data_split], data[1][data_split:]\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "sort_index = np.argsort(labels, axis=0)\n",
    "\n",
    "sorted_images = images[sort_index]\n",
    "sorted_labels = labels[sort_index]\n",
    "\n",
    "sorted_data = sorted_images, sorted_labels\n",
    "\n",
    "test_data = test_images, test_labels\n",
    "\n",
    "image = np.asarray(sorted_images[1]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(decoder[sorted_labels[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "posted-therapy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n",
      "CPU times: user 1.72 ms, sys: 587 µs, total: 2.3 ms\n",
      "Wall time: 1.82 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.set_printoptions(threshold=2 ** 10 + 1)\n",
    "print(sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inner-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    \"\"\"From https://towardsdatascience.com/how-to-implement-an-adam-optimizer-from-scratch-76e7b217f1cc\n",
    "        each class has its own key for a dict with the respective values in it, this speeds up training but slows down prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_keys=N, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        \"\"\"Inits the values used in adam\"\"\"\n",
    "        self.m_dw = {key: 0 for key in range(num_of_keys)}\n",
    "        self.v_dw = {key: 0 for key in range(num_of_keys)}\n",
    "        self.m_db = {key: 0 for key in range(num_of_keys)}\n",
    "        self.v_db = {key: 0 for key in range(num_of_keys)}\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "    def update(self, key, t, w, b, dw, db):\n",
    "        \"\"\"Updates the values used in the adam optimizer\"\"\"\n",
    "        ## dw, db are from current minibatch\n",
    "        ## momentum beta 1\n",
    "        # *** weights *** #\n",
    "        self.m_dw[key] = self.beta1*self.m_dw[key] + (1-self.beta1)*dw\n",
    "        # *** biases *** #\n",
    "        self.m_db[key] = self.beta1*self.m_db[key] + (1-self.beta1)*db\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** weights *** #\n",
    "        self.v_dw[key] = self.beta2*self.v_dw[key] + (1-self.beta2)*(dw**2)\n",
    "        # *** biases *** #\n",
    "        self.v_db[key] = self.beta2*self.v_db[key] + (1-self.beta2)*(db)\n",
    "\n",
    "        ## bias correction\n",
    "        m_dw_corr = self.m_dw[key]/(1-self.beta1**t + self.epsilon)\n",
    "        m_db_corr = self.m_db[key]/(1-self.beta1**t + self.epsilon)\n",
    "        v_dw_corr = self.v_dw[key]/(1-self.beta2**t + self.epsilon)\n",
    "        v_db_corr = self.v_db[key]/(1-self.beta2**t + self.epsilon)\n",
    "\n",
    "        ## update weights and biases\n",
    "        w = w + self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon))\n",
    "        b = b + self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n",
    "        return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2bdb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Forward_and_backward:\n",
    "    \"\"\"Bassed off of:\n",
    "        https://arxiv.org/pdf/1908.08385.pdf\n",
    "        This model uses quantum simulation to train, while it is not currently desined to work on quantum circuits it would only take some\n",
    "        minor adjustments to make it work. However I do not have access to the arichtechture I need to run classification on. This model needs\n",
    "        one qubit per class, so task such as binary classification would be very quick.\n",
    "    \"\"\"\n",
    "    def __init__(self, N, data, test_data, num_of_it):\n",
    "        \"\"\"Inits values:\n",
    "            self.num_of_it: number of iterations\n",
    "            self.target_N: the number of classes\n",
    "            self.data: the data to classify and train with\n",
    "            self.test_data: the test data\n",
    "            self.alpha: a learnable parameter simular to biases\n",
    "            self.total_error: The total error per class starting with class 0 and ending at class N. Is a dict containing the errors per epoch\n",
    "            self.set_lie_alge: If true gets a new set of lie algebras if flase saves the current set for calculations\n",
    "            self.cumulative_error: the cumulative error over iterations\n",
    "            \"\"\"\n",
    "        self.num_of_it = num_of_it\n",
    "        self.target_N = N\n",
    "        data_split = int(data[0].shape[0] * 0.75)\n",
    "        self.data = data\n",
    "        self.test_data = test_data\n",
    "        self.alpha = {} # kind of like biases\n",
    "        self.total_error = {}\n",
    "        self.set_lie_alge = True\n",
    "        self.cumulative_error = 0\n",
    "    \n",
    "    def H(self):\n",
    "        \"\"\"H is a generalized Haadamard gate, in simple terms it distributes the probability of the outcomes evenly\"\"\"\n",
    "        epsilon = 1e-05\n",
    "        term0 = self.A()\n",
    "        term1 = self.SU_Nm1\n",
    "        term2 = np.sum(self.lie_alge)\n",
    "        term3 = np.sum(self.alpha[self.i] * (1 + 0j))\n",
    "        term4 = np.exp(1j * term2 * term3) + epsilon\n",
    "        \n",
    "        euler = term0 * term1 * term4\n",
    "        euler = OneQubitEulerDecomposer(\"ZYZ\").angles(euler)\n",
    "        \n",
    "        def map_circuit(k, qc_k):\n",
    "            \"\"\"This sub function maps all the circuits to eachother entangleing the values, so that when one is measured all respond\"\"\"\n",
    "            for i in range(self.target_N):\n",
    "                try:\n",
    "                    qc_k.cx(k, i) @ (np.asarray(euler)[np.newaxis]).T\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        qr = QuantumRegister(self.target_N, \"qreg\")\n",
    "        qc_k = QuantumCircuit(qr, name=\"qc_k\")\n",
    "        \n",
    "        for k in range(1, self.target_N + 1):\n",
    "            qc_k.initialize([np.sqrt(1/2), np.sqrt(1/2)], qubits=k - 1)\n",
    "        \n",
    "        for k in range(self.target_N):\n",
    "            map_circuit(k, qc_k)\n",
    "\n",
    "        op = PrimitiveOp(qc_k)\n",
    "        h = []\n",
    "        for i in range(self.x.shape[2]):\n",
    "            h.append(op)\n",
    "            \n",
    "        h = np.asarray(h, dtype=object)[:np.newaxis]\n",
    "        H_op = np.asarray(h / np.sqrt(self.target_N, dtype=np.complex_), dtype=object) \n",
    "        \n",
    "        return H_op\n",
    "        \n",
    "    def quNit(self, SU_of_N):\n",
    "        \"\"\"A quNit is a quantum uint, similar to how a byte is made up of bits\"\"\"\n",
    "        S3 =np.zeros(shape=(self.target_N, self.target_N), dtype=np.complex_)\n",
    "        np.fill_diagonal(S3, -(self.target_N - 1) / 2)\n",
    "        sum_of_weights = np.sum(np.asarray([w @ x for w, x in zip(self.W[self.i], self.x)]), axis=0)\n",
    "        Z = np.exp((1j) * S3) \n",
    "\n",
    "        self.lie_alge = self.lie_algebra(SU_of_N)\n",
    "        \n",
    "        qn = Z @ (sum_of_weights @ self.H()).T\n",
    "        return qn\n",
    "\n",
    " ##################################################   \n",
    "\n",
    "    def A(self):\n",
    "        \"\"\"Bassed off of A in the paper https://arxiv.org/pdf/1908.08385.pdf found in formula 3\"\"\"\n",
    "        a = []\n",
    "        epsilon = 1e-05\n",
    "        \n",
    "        for k in range(2, self.target_N + 1):\n",
    "            term0 = 1j * self.lie_alge[2]\n",
    "            term1 = self.alpha[self.i][(2 * k - 3) - 1]\n",
    "            term2 = np.exp(term0 * term1)\n",
    "            term3 = 1j * self.lie_alge[((k - 1) ** 2 + 1) - 1]\n",
    "            term4 = self.alpha[self.i][(2 * (k - 1)) - 1]\n",
    "            term5 = np.exp(term3 * term4)\n",
    "            term6 = term2 * term5\n",
    "            val = term6\n",
    "            a.append(val + epsilon)\n",
    "        \n",
    "        return np.prod(a) \n",
    "    \n",
    "    def SU_of_N(self, n):\n",
    "        \"\"\"Technicly I am using the special orthogonal group of N instead of the special unitary group of N, but I could not find a modual to calculate\n",
    "            high dimensonal SU of N so this had to do, overall it will hurt my speed and accuracy some but should still work.\"\"\"\n",
    "        son = SpecialOrthogonal(n=n, point_type='matrix')\n",
    "        metric = son.bi_invariant_metric\n",
    "\n",
    "        data = son.random_uniform(n_samples=(n))\n",
    "\n",
    "        tpca = TangentPCA(metric=metric, n_components=(n))  ## SELF.TARGET_N?\n",
    "        tpca = tpca.fit(data)\n",
    "        tangent_projected_data = tpca.transform(data)\n",
    "\n",
    "        return tangent_projected_data\n",
    "\n",
    "    def lie_algebra(self, SU_N):\n",
    "        \"\"\"Some of the lie algebras of the group SO of N, lie algebra deals with the space near the origin of SO of N and plays a cruical role in\n",
    "            optimizing the model.\n",
    "        \"\"\"\n",
    "        if self.set_lie_alge == True:\n",
    "            self.set_lie_alge = False\n",
    "            i = 0\n",
    "            epsilon = 1e-10\n",
    "            lie_algebras = []\n",
    "            while i < self.target_N ** 2:\n",
    "                # print(\"working on lie algebra {} / {}\".format(i, self.target_N ** 2))\n",
    "                delta = epsilon * np.random.uniform(low=-10, high=10, size=(1))\n",
    "                mat = np.full((self.target_N, self.target_N), delta)\n",
    "                np.fill_diagonal(mat, 0)\n",
    "                \n",
    "                if not np.linalg.det(mat) or np.isclose(delta, 0, atol=epsilon):\n",
    "                    continue\n",
    "                else:\n",
    "                    i += 1\n",
    "                    lie = mat \n",
    "                    lie_algebras.append(lie)\n",
    "\n",
    "            return np.asarray(lie_algebras, dtype= complex)\n",
    "\n",
    "        else:\n",
    "            return self.lie_alge\n",
    "    ############################################\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        \"\"\"The forward step. This takes all of the other parts and ties them together in the forward step. It measures the quantum circuit and returns\n",
    "            a state vector. It also provides a probability distribution for the values, sometimes the distribution can be off and this can upset the values\n",
    "            but given enough itterations it corrects over time.\"\"\"\n",
    "        SU_N = self.SU_N\n",
    "        ket_x = self.quNit(SU_N)\n",
    "        \n",
    "        ket_x = SU_N @ ket_x\n",
    "\n",
    "        ket_x_list = []\n",
    "\n",
    "        for k, op in enumerate(ket_x):\n",
    "            cr = ClassicalRegister(self.target_N, \"creg{}\".format(k))\n",
    "            qc = my_expectation.convert(op)\n",
    "            qc = qc.to_circuit()\n",
    "            qc.add_register(cr)\n",
    "            qc.measure_all([val for val in range(self.target_N - 1)])\n",
    "            qobj = assemble(qc, shots= 2 ** self.target_N)\n",
    "            job = simulator.run(qobj)\n",
    "            vec = job.result().get_statevector(qc, decimals=10)\n",
    "            ket_x_list.append(vec)\n",
    "        \n",
    "        ket_x = np.asarray(ket_x_list)\n",
    "\n",
    "        def Purity(N, ket_x):\n",
    "            \"\"\"This measures the purity of the quantum circuits it is used to deterimine how accurate the probabilities are.\"\"\"\n",
    "            bra_x = np.asmatrix(ket_x).H\n",
    "            \n",
    "            return ((ket_x @ bra_x) / N) ** 2\n",
    "            \n",
    "        Pa = Purity(self.target_N, ket_x)\n",
    "        Pa = np.diag(Pa)\n",
    "        Pb = np.argmax(Pa)\n",
    "        print(\"probibility distiribution = \", Pa.real)\n",
    "\n",
    "        return Pb, ket_x\n",
    "\n",
    "    def backward(self, pred_dict):\n",
    "        \"\"\"This is the back propagation step, to some degree along with the loss function.\"\"\"\n",
    "        SU_N = self.SU_N\n",
    "        qc = self.H()\n",
    "        Mk = self.target_N\n",
    "        \n",
    "        ket_x = pred_dict[decoder[self.i]][1]\n",
    "        \n",
    "        Pk = np.sum((np.matrix(ket_x) @ np.matrix(ket_x).H)  / Mk)\n",
    "        \n",
    "        Pk = np.asarray(np.asmatrix(SU_N) * Pk * np.asmatrix(SU_N).H, dtype=np.complex_)\n",
    "        Pk = np.diagonal(Pk.real)\n",
    "\n",
    "        self.total_error[self.i] = (1 - Pk) / Mk\n",
    "        \n",
    "        self.cumulative_error = (Pk) / (self.j + 1) + (self.cumulative_error * 0.9) # 0.9 is a decay rate\n",
    "        \n",
    "        for i, value in enumerate(self.cumulative_error):\n",
    "            print(\"Total error of {} = {}\".format(i, (value)))\n",
    "        print(\"Prediction for class = \", np.argmax(self.cumulative_error))\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"This is the primary driver for training the quantum circuits, there are some safety percautions built in to handle the rare occuracne of\n",
    "            numerical instability. It uses an adam optimizer, and takes a foward and backward step per iteration. In this model each epoch is one class\n",
    "            and the iterations are how many times the class is run through the quantum circuit.\n",
    "        \"\"\"\n",
    "        adam = AdamOptim(num_of_keys=self.target_N)\n",
    "        pred_dict = {}\n",
    "        init_W = True\n",
    "        sums_of_errors = []\n",
    "        self.W = {}\n",
    "        self.SU_N = self.SU_of_N(self.target_N)\n",
    "        self.SU_Nm1 = self.SU_of_N(self.target_N - 1)\n",
    "        \n",
    "        i = 0\n",
    "        j = 0\n",
    "        \n",
    "        sorted_images = self.data[0].squeeze(axis=(-1))\n",
    "        print(sorted_images.shape)\n",
    "        sorted_labels = self.data[1]\n",
    "        \n",
    "        for i in range(self.target_N):\n",
    "            try_count = 0\n",
    "            self.i = i\n",
    "            init_W = True\n",
    "            self.alpha[self.i] = np.arange(start=1, stop=self.target_N ** 2 + 1, dtype=np.complex_)\n",
    "            \n",
    "            y = sorted_labels[sorted_labels == i]\n",
    "            self.x = sorted_images[sorted_labels == i]\n",
    "            print(self.x.shape)\n",
    "            \n",
    "            while j < self.num_of_it:\n",
    "                print(\"working on {}s\".format(decoder[i]))\n",
    "                print(\"iteration {} / {}\".format(j + 1, self.num_of_it))\n",
    "                try:\n",
    "                    self.j = j\n",
    "                    if init_W:\n",
    "                        print(\"init W\")\n",
    "                        self.W[self.i] = np.random.random(size=(self.x.shape[0], self.target_N, self.x.shape[2])) # learnable similar to weights\n",
    "\n",
    "                    pred_dict[decoder[i]] = self.forward()\n",
    "                    self.backward(pred_dict)\n",
    "\n",
    "                    dw = (np.asarray([w @ w.T for w in self.W[self.i]], dtype=np.complex_) @ self.total_error[self.i])[:, :, np.newaxis]\n",
    "                    db = self.alpha[self.i]  @ self.alpha[self.i].T * np.sum(self.total_error[self.i])\n",
    "\n",
    "                    self.W[self.i], self.alpha[self.i] = adam.update(key=i, t=j, w=self.W[self.i], b=self.alpha[self.i], dw=dw, db=db)\n",
    "\n",
    "                    init_W = False\n",
    "\n",
    "                    j += 1\n",
    "                except(ValueError) as e:\n",
    "                    print(\"==========Numerical instability occured retrying calculations==========\")\n",
    "                    print(\"==========Calculations retried {} / 10 times==========\".format(try_count + 1))\n",
    "                    print(e)\n",
    "                    try_count += 1\n",
    "                    self.set_lie_alge = True\n",
    "                    if try_count == 10:\n",
    "                        print(\"==========Major error occured rerun program==========\")\n",
    "                        return 1\n",
    "            sums_of_errors.append(self.cumulative_error)\n",
    "            self.cumulative_error = 0\n",
    "            j = 0\n",
    "            \n",
    "    def predict(self):\n",
    "        \"\"\"Uses a stripped down version of train to make predictions. For each image in question it will go through all of the classes and determine a\n",
    "           likely hood of the image belonging to the class.\"\"\"\n",
    "        self.SU_N = self.SU_of_N(self.target_N)\n",
    "        self.SU_Nm1 = self.SU_of_N(self.target_N - 1)\n",
    "        pred_dict = {}\n",
    "        sums_of_errors = []\n",
    "        \n",
    "        i = 0\n",
    "        j = 0\n",
    "        \n",
    "        images = self.test_data[0].squeeze(axis=(-1))\n",
    "        self.labels = test_data[1]\n",
    "        print(sorted_images.shape)\n",
    "        sorted_labels = self.data[1]\n",
    "        for k, value in enumerate(images):\n",
    "            self.x = value\n",
    "            print(sorted_labels[k])\n",
    "            for i in range(self.target_N):\n",
    "                try_count = 0\n",
    "                self.i = i\n",
    "                self.x = images\n",
    "\n",
    "                while j < 1:\n",
    "                    try:\n",
    "                        self.j = j\n",
    "\n",
    "                        pred_dict[decoder[i]] = self.forward()\n",
    "                        self.backward(pred_dict)\n",
    "\n",
    "                        j += 1\n",
    "                    except(ValueError) as e:\n",
    "                        print(\"==========Numerical instability occured retrying calculations==========\")\n",
    "                        print(\"==========Calculations retried {} / 10 times==========\".format(try_count + 1))\n",
    "                        print(e)\n",
    "                        try_count += 1\n",
    "\n",
    "                        if try_count == 10:\n",
    "                            print(\"==========Major error occured rerun program==========\")\n",
    "                            return 1\n",
    "                sums_of_errors.append(self.cumulative_error)\n",
    "                self.cumulative_error = 0\n",
    "                j = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "streaming-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 4 µs, total: 16 µs\n",
      "Wall time: 21.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = Forward_and_backward(N, sorted_data, test_data, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 28, 28)\n",
      "(606, 28, 28)\n",
      "working on 0s\n",
      "iteration 1 / 50\n",
      "init W\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-bosnia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-adobe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304efcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55acf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
