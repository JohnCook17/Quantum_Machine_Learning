{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sublime-filter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 1.31 s, total: 4.2 s\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gzip\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organized-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 161 ms, sys: 847 µs, total: 162 ms\n",
      "Wall time: 208 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Useful additional packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.version.version\n",
    "np.seterr(all=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 90.2 ms, total: 1.59 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, execute\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.quantum_info import state_fidelity, OneQubitEulerDecomposer\n",
    "from qiskit import  Aer, transpile, IBMQ, assemble\n",
    "from qiskit.circuit.library import CHGate\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit.aqua.operators import PrimitiveOp, CircuitStateFn\n",
    "from qiskit.aqua.operators.primitive_ops import MatrixOp\n",
    "from qiskit.aqua.operators.converters import CircuitSampler\n",
    "from qiskit.aqua.operators.expectations import MatrixExpectation\n",
    "from qiskit.aqua.operators.list_ops import ComposedOp\n",
    "from qiskit.aqua.operators import ListOp\n",
    "from qiskit.aqua.components.initial_states import Zero\n",
    "import qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understood-machinery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 142 ms, sys: 24.5 ms, total: 167 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from geomstats.geometry.special_orthogonal import SpecialOrthogonal\n",
    "from geomstats.learning.pca import TangentPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vulnerable-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__init__.discover_credentials:INFO:2021-05-05 02:35:25,461: Using credentials from qiskitrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 30.2 ms, total: 165 ms\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "provider = IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfied-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prescription-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 ms, sys: 568 µs, total: 2.6 ms\n",
      "Wall time: 2.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print(Aer.backends())\n",
    "simulator = Aer.get_backend(\"statevector_simulator\") # unable to run on current quantum architechture, due to circuit incompatability\n",
    "my_sampler = CircuitSampler(backend=simulator, attach_results=True, param_qobj=False)\n",
    "my_expectation = MatrixExpectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desirable-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 µs, sys: 4 µs, total: 18 µs\n",
      "Wall time: 23.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# EMNIST decoder\n",
    "\n",
    "decoder = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 8.17 ms, total: 8.17 ms\n",
      "Wall time: 28.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "images_raw = gzip.open(\"data/MNIST/MNIST_GZ/train-images-idx3-ubyte.gz\", \"r\")\n",
    "labels_raw = gzip.open(\"data/MNIST/MNIST_GZ/train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "\n",
    "image_size = 28\n",
    "num_images = 8192 # how many images total\n",
    "\n",
    "images_raw.read(16) # reads the data type\n",
    "labels_raw.read(8) # reads the data type\n",
    "\n",
    "def get_data(images, labels):\n",
    "    buf_images = images.read(image_size * image_size * num_images)\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(num_images, image_size, image_size, 1)\n",
    "    \n",
    "    buf_labels = labels.read(num_images)\n",
    "    labels = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int32)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intense-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_num_cls(data):\n",
    "    labels = np.array(data[1])\n",
    "    one_hot_labels = to_categorical(labels)\n",
    "    \n",
    "    return one_hot_labels.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hired-pakistan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  10\n",
      "(6144, 28, 28, 1)\n",
      "(6144,)\n",
      "(2048, 28, 28, 1)\n",
      "(2048,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print images\n",
    "data = get_data(images_raw, labels_raw)\n",
    "N = get_num_cls(data)\n",
    "print(\"Number of classes = \", N)\n",
    "data_split = int(data[0].shape[0] * 0.75)\n",
    "images, test_images = data[0][0: data_split], data[0][data_split:]\n",
    "labels, test_labels = data[1][0: data_split], data[1][data_split:]\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "sort_index = np.argsort(labels, axis=0)\n",
    "\n",
    "sorted_images = images[sort_index]\n",
    "sorted_labels = labels[sort_index]\n",
    "\n",
    "sorted_data = sorted_images, sorted_labels\n",
    "\n",
    "test_data = test_images, test_labels\n",
    "\n",
    "image = np.asarray(sorted_images[1]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(decoder[sorted_labels[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "posted-therapy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n",
      "CPU times: user 305 µs, sys: 85 µs, total: 390 µs\n",
      "Wall time: 398 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.set_printoptions(threshold=2 ** 10 + 1)\n",
    "print(sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inner-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    \"\"\"From https://towardsdatascience.com/how-to-implement-an-adam-optimizer-from-scratch-76e7b217f1cc\n",
    "        each class has its own key for a dict with the respective values in it, this speeds up training but slows down prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_keys=N, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        \"\"\"Inits the values used in adam\"\"\"\n",
    "        self.m_dw = {key: 0 for key in range(num_of_keys)}\n",
    "        self.v_dw = {key: 0 for key in range(num_of_keys)}\n",
    "        self.m_db = {key: 0 for key in range(num_of_keys)}\n",
    "        self.v_db = {key: 0 for key in range(num_of_keys)}\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "    def update(self, key, t, w, b, dw, db):\n",
    "        \"\"\"Updates the values used in the adam optimizer\"\"\"\n",
    "        ## dw, db are from current minibatch\n",
    "        ## momentum beta 1\n",
    "        # *** weights *** #\n",
    "        self.m_dw[key] = self.beta1*self.m_dw[key] + (1-self.beta1)*dw\n",
    "        # *** biases *** #\n",
    "        self.m_db[key] = self.beta1*self.m_db[key] + (1-self.beta1)*db\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** weights *** #\n",
    "        self.v_dw[key] = self.beta2*self.v_dw[key] + (1-self.beta2)*(dw**2)\n",
    "        # *** biases *** #\n",
    "        self.v_db[key] = self.beta2*self.v_db[key] + (1-self.beta2)*(db)\n",
    "\n",
    "        ## bias correction\n",
    "        m_dw_corr = self.m_dw[key]/(1-self.beta1**t + self.epsilon)\n",
    "        m_db_corr = self.m_db[key]/(1-self.beta1**t + self.epsilon)\n",
    "        v_dw_corr = self.v_dw[key]/(1-self.beta2**t + self.epsilon)\n",
    "        v_db_corr = self.v_db[key]/(1-self.beta2**t + self.epsilon)\n",
    "\n",
    "        ## update weights and biases\n",
    "        w = w + self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon))\n",
    "        b = b + self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n",
    "        return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "242d0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Forward_and_backward:\n",
    "    \"\"\"Bassed off of:\n",
    "        https://arxiv.org/pdf/1908.08385.pdf\n",
    "        This model uses quantum simulation to train, while it is not currently desined to work on quantum circuits it would only take some\n",
    "        minor adjustments to make it work. However I do not have access to the arichtechture I need to run classification on. This model needs\n",
    "        one qubit per class, so task such as binary classification would be very quick.\n",
    "    \"\"\"\n",
    "    def __init__(self, N, data, test_data, num_of_it):\n",
    "        \"\"\"Inits values:\n",
    "            self.num_of_it: number of iterations\n",
    "            self.target_N: the number of classes\n",
    "            self.data: the data to classify and train with\n",
    "            self.test_data: the test data\n",
    "            self.alpha: a learnable parameter simular to biases\n",
    "            self.total_error: The total error per class starting with class 0 and ending at class N. Is a dict containing list of the errors per epoch\n",
    "            self.set_lie_alge: If true gets a new set of lie algebras if flase saves the current set for calculations\n",
    "            self.cumulative_error: the cumulative error over iterations\n",
    "            \"\"\"\n",
    "        self.num_of_it = num_of_it\n",
    "        self.target_N = N\n",
    "        self.data = data\n",
    "        self.test_data = test_data\n",
    "        self.alpha = {} # kind of like biases\n",
    "        self.total_error = {key: [] for key in range(self.target_N)}\n",
    "        self.set_lie_alge = True\n",
    "        self.cumulative_error = 0\n",
    "        self.predict_mode = False\n",
    "    \n",
    "    def H(self):\n",
    "        \"\"\"H is a generalized Haadamard gate, in simple terms it distributes the probability of the outcomes evenly\"\"\"\n",
    "        epsilon = 1e-05\n",
    "        term0 = self.A()\n",
    "        term1 = self.SU_Nm1\n",
    "        term2 = np.sum(self.lie_alge)\n",
    "        term3 = np.sum(self.alpha[self.i] * (1 + 0j))\n",
    "        term4 = np.exp(1j * term2 * term3) + epsilon\n",
    "        \n",
    "        euler = term0 * term1 * term4\n",
    "        euler = OneQubitEulerDecomposer(\"ZYZ\").angles(euler)\n",
    "        \n",
    "        def map_circuit(k, qc_k):\n",
    "            \"\"\"This sub function maps all the circuits to eachother entangleing the values, so that when one is measured all respond\"\"\"\n",
    "            for i in range(self.target_N):\n",
    "                try:\n",
    "                    qc_k.cx(k, i) @ (np.asarray(euler)[np.newaxis]).T\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        qr = QuantumRegister(self.target_N, \"qreg\")\n",
    "        qc_k = QuantumCircuit(qr, name=\"qc_k\")\n",
    "        \n",
    "        for k in range(1, self.target_N + 1):\n",
    "            qc_k.initialize([np.sqrt(1/2), np.sqrt(1/2)], qubits=k - 1)\n",
    "        \n",
    "        for k in range(self.target_N):\n",
    "            map_circuit(k, qc_k)\n",
    "\n",
    "        op = PrimitiveOp(qc_k)\n",
    "        h = []\n",
    "        for i in range(self.x.shape[2]):\n",
    "            h.append(op)\n",
    "            \n",
    "        h = np.asarray(h, dtype=object)[:np.newaxis]\n",
    "        H_op = np.asarray(h / np.sqrt(self.target_N, dtype=np.complex_), dtype=object) \n",
    "        \n",
    "        return H_op\n",
    "        \n",
    "    def quNit(self, SU_of_N):\n",
    "        \"\"\"A quNit is a quantum uint, similar to how a byte is made up of bits\"\"\"\n",
    "        S3 =np.zeros(shape=(self.target_N, self.target_N), dtype=np.complex_)\n",
    "        np.fill_diagonal(S3, -(self.target_N - 1) / 2)\n",
    "        sum_of_weights = np.sum(np.asarray([w @ x for w, x in zip(self.W[self.i], self.x)]), axis=0)\n",
    "        Z = np.exp((1j) * S3) \n",
    "\n",
    "        self.lie_alge = self.lie_algebra(SU_of_N)\n",
    "        \n",
    "        qn = Z @ (sum_of_weights @ self.H()).T\n",
    "        return qn\n",
    "\n",
    " ##################################################   \n",
    "\n",
    "    def A(self):\n",
    "        \"\"\"Bassed off of A in the paper https://arxiv.org/pdf/1908.08385.pdf found in formula 3\"\"\"\n",
    "        a = []\n",
    "        epsilon = 1e-05\n",
    "        \n",
    "        for k in range(2, self.target_N + 1):\n",
    "            term0 = 1j * self.lie_alge[2]\n",
    "            term1 = self.alpha[self.i][(2 * k - 3) - 1]\n",
    "            term2 = np.exp(term0 * term1)\n",
    "            term3 = 1j * self.lie_alge[((k - 1) ** 2 + 1) - 1]\n",
    "            term4 = self.alpha[self.i][(2 * (k - 1)) - 1]\n",
    "            term5 = np.exp(term3 * term4)\n",
    "            term6 = term2 * term5\n",
    "            val = term6\n",
    "            a.append(val + epsilon)\n",
    "        \n",
    "        return np.prod(a) \n",
    "    \n",
    "    def SU_of_N(self, n):\n",
    "        \"\"\"Technicly I am using the special orthogonal group of N instead of the special unitary group of N, but I could not find a modual to calculate\n",
    "            high dimensonal SU of N so this had to do, overall it will hurt my speed and accuracy some but should still work.\"\"\"\n",
    "        son = SpecialOrthogonal(n=n, point_type='matrix')\n",
    "        metric = son.bi_invariant_metric\n",
    "\n",
    "        data = son.random_uniform(n_samples=(n))\n",
    "\n",
    "        tpca = TangentPCA(metric=metric, n_components=(n))  ## SELF.TARGET_N?\n",
    "        tpca = tpca.fit(data)\n",
    "        tangent_projected_data = tpca.transform(data)\n",
    "\n",
    "        return tangent_projected_data\n",
    "\n",
    "    def lie_algebra(self, SU_N):\n",
    "        \"\"\"Some of the lie algebras of the group SO of N, lie algebra deals with the space near the origin of SO of N and plays a cruical role in\n",
    "            optimizing the model.\n",
    "        \"\"\"\n",
    "        if self.set_lie_alge == True:\n",
    "            self.set_lie_alge = False\n",
    "            i = 0\n",
    "            epsilon = 1e-10\n",
    "            lie_algebras = []\n",
    "            while i < self.target_N ** 2:\n",
    "                print(\"\\rworking on lie algebra {} / {}\".format(i + 1, self.target_N ** 2), end=\"\")\n",
    "                delta = epsilon * np.random.uniform(low=-10, high=10, size=(1))\n",
    "                mat = np.full((self.target_N, self.target_N), delta)\n",
    "                np.fill_diagonal(mat, 0)\n",
    "                \n",
    "                if not np.linalg.det(mat) or np.isclose(delta, 0, atol=epsilon):\n",
    "                    continue\n",
    "                else:\n",
    "                    i += 1\n",
    "                    lie = mat \n",
    "                    lie_algebras.append(lie)\n",
    "\n",
    "            return np.asarray(lie_algebras, dtype= complex)\n",
    "\n",
    "        else:\n",
    "            return self.lie_alge\n",
    "    ############################################\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        \"\"\"The forward step. This takes all of the other parts and ties them together in the forward step. It measures the quantum circuit and returns\n",
    "            a state vector. It also provides a probability distribution for the values, sometimes the distribution can be off and this can upset the values\n",
    "            but given enough itterations it corrects over time.\"\"\"\n",
    "        SU_N = self.SU_N\n",
    "        ket_x = self.quNit(SU_N)\n",
    "        \n",
    "        ket_x = SU_N @ ket_x\n",
    "\n",
    "        ket_x_list = []\n",
    "\n",
    "        for k, op in enumerate(ket_x):\n",
    "            cr = ClassicalRegister(self.target_N, \"creg{}\".format(k))\n",
    "            qc = my_expectation.convert(op)\n",
    "            qc = qc.to_circuit()\n",
    "            qc.add_register(cr)\n",
    "            qc.measure_all([val for val in range(self.target_N - 1)])\n",
    "            qobj = assemble(qc, shots= 2 ** self.target_N)\n",
    "            job = simulator.run(qobj)\n",
    "            vec = job.result().get_statevector(qc, decimals=10)\n",
    "            ket_x_list.append(vec)\n",
    "        \n",
    "        ket_x = np.asarray(ket_x_list)\n",
    "\n",
    "        def Purity(N, ket_x):\n",
    "            \"\"\"This measures the purity of the quantum circuits it is used to deterimine how accurate the probabilities are.\"\"\"\n",
    "            bra_x = np.asmatrix(ket_x).H\n",
    "            \n",
    "            return ((ket_x @ bra_x) / N) ** 2\n",
    "            \n",
    "        Pa = Purity(self.target_N, ket_x)\n",
    "        Pa = np.diag(Pa)\n",
    "        Pb = np.argmax(Pa)\n",
    "        print(\"\\nprobibility distiribution = \", Pa.real)\n",
    "\n",
    "        return Pb, ket_x\n",
    "\n",
    "    def backward(self, pred_dict):\n",
    "        \"\"\"This is the back propagation step, to some degree along with the loss function.\"\"\"\n",
    "        SU_N = self.SU_N\n",
    "        qc = self.H()\n",
    "        Mk = self.target_N * self.target_N\n",
    "        \n",
    "        ket_x = pred_dict[decoder[self.i]][1]\n",
    "        \n",
    "        Pk = np.sum((np.matrix(ket_x) @ np.matrix(ket_x).H)  / Mk)\n",
    "        \n",
    "        Pk = np.asarray(np.asmatrix(SU_N) * Pk * np.asmatrix(SU_N).H, dtype=np.complex_)\n",
    "        Pk = np.diagonal(Pk.real)\n",
    "\n",
    "        self.total_error[self.i].append((Pk) / Mk) # list of all errors stored in a dict per class\n",
    "        \n",
    "        self.cumulative_error = ((Pk) / (self.j + 1)) + (self.cumulative_error * 0.7) # decimal here is a decay rate, j + 1 is number of iterations\n",
    "        \n",
    "        if self.j <= 5 and not self.predict_mode:\n",
    "            # normalizing error for first iteration to reduce random variance\n",
    "            self.total_error[self.i][self.j] = self.total_error[self.i][self.j] / np.linalg.norm(self.total_error[self.i][self.j])\n",
    "            self.total_error[self.i][self.j][self.i] -= 1 # seeds the class\n",
    "            self.cumulative_error[self.i] -= 1 # seeds the class \n",
    "        \n",
    "        for i, value in enumerate(self.cumulative_error):\n",
    "            print(\"Total error of {} = {}\".format(i, (value)))\n",
    "        print(\"Prediction for class based off of total = \", np.argmin(self.cumulative_error))\n",
    "        print(\"Prediction for class based off of current = \", np.argmin(self.total_error[self.i][self.j]))\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.j != 0:\n",
    "            change = np.argmin(self.total_error[self.i][:self.j] - np.sum(self.total_error[self.i][0:self.j - 1], axis=(0))) # optimization gets harder less change\n",
    "            print(\"Prediction for class based off of least change due to increasing gradient = \", change)\n",
    "        elif self.j >= 1:\n",
    "            change = np.argmin(self.total_error[self.i][:self.j] - np.sum(self.total_error[self.i][0:self.j - 1], axis=(0, 1))) # optimization gets harder less change\n",
    "            print(\"Prediction for class based off of least change due to increasing gradient = \", change)\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.min(self.cumulative_error)\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"This is the primary driver for training the quantum circuits, there are some safety percautions built in to handle the rare occuracne of\n",
    "            numerical instability. It uses an adam optimizer, and takes a foward and backward step per iteration. In this model each epoch is one class\n",
    "            and the iterations are how many times the class is run through the quantum circuit.\n",
    "        \"\"\"\n",
    "        adam = AdamOptim(num_of_keys=self.target_N)\n",
    "        pred_dict = {}\n",
    "        init_W = True\n",
    "        sums_of_errors = []\n",
    "        self.W = {}\n",
    "        self.SU_N = self.SU_of_N(self.target_N)\n",
    "        self.SU_Nm1 = self.SU_of_N(self.target_N - 1)\n",
    "        \n",
    "        i = 0\n",
    "        j = 0\n",
    "        \n",
    "        sorted_images = self.data[0].squeeze(axis=(-1)) / 255 # for images\n",
    "        sorted_labels = self.data[1]\n",
    "        \n",
    "        plt.imshow(sorted_images[0] * 255)\n",
    "        plt.show()\n",
    "        print(sorted_labels[0])\n",
    "        \n",
    "        for i in range(self.target_N):\n",
    "            try_count = 0\n",
    "            self.i = i\n",
    "            init_W = True\n",
    "            self.alpha[self.i] = np.arange(start=1, stop=self.target_N ** 2 + 1, dtype=np.complex_)\n",
    "            \n",
    "            y = sorted_labels[sorted_labels == i]\n",
    "            self.x = sorted_images[sorted_labels == i]\n",
    "            print(self.x.shape)\n",
    "            \n",
    "            while j < self.num_of_it:\n",
    "                print(\"working on {}s\".format(decoder[i]))\n",
    "                print(\"iteration {} / {}\".format(j + 1, self.num_of_it))\n",
    "                self.set_lie_alge = True\n",
    "                try:\n",
    "                    self.j = j\n",
    "                    if init_W:\n",
    "                        print(\"init W\")\n",
    "                        self.W[self.i] = np.random.uniform(low=-0.25, high=0.25, size=(self.x.shape[0], self.target_N, self.x.shape[2]))# learnable similar to weights\n",
    "\n",
    "                    pred_dict[decoder[i]] = self.forward()\n",
    "                    self.backward(pred_dict)\n",
    "\n",
    "                    dw = (np.asarray([w @ w.T for w in self.W[self.i]], dtype=np.complex_) @ self.total_error[self.i][self.j])[:, :, np.newaxis]\n",
    "                    db = self.alpha[self.i]  @ self.alpha[self.i].T * np.sum(self.total_error[self.i][self.j])\n",
    "\n",
    "                    self.W[self.i], self.alpha[self.i] = adam.update(key=i, t=j, w=self.W[self.i], b=self.alpha[self.i], dw=dw, db=db)\n",
    "\n",
    "                    init_W = False\n",
    "\n",
    "                    j += 1\n",
    "                except(ValueError) as e:\n",
    "                    print(\"==========Numerical instability occured retrying calculations==========\")\n",
    "                    print(\"==========Calculations retried {} / 10 times==========\".format(try_count + 1))\n",
    "                    print(e)\n",
    "                    try_count += 1\n",
    "                    if try_count == 10:\n",
    "                        print(\"==========Major error occured rerun program==========\")\n",
    "                        return 1\n",
    "            sums_of_errors.append(self.cumulative_error)\n",
    "            self.cumulative_error = 0\n",
    "            j = 0\n",
    "            \n",
    "        return sums_of_errors\n",
    "            \n",
    "    def predict(self):\n",
    "        \"\"\"Uses a stripped down version of train to make predictions. For each image in question it will go through all of the classes and determine a\n",
    "           likely hood of the image belonging to the class.\"\"\"\n",
    "        self.SU_N = self.SU_of_N(self.target_N)\n",
    "        self.SU_Nm1 = self.SU_of_N(self.target_N - 1)\n",
    "        sums_of_errors = []\n",
    "        self.predict_mode=True\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        images = self.test_data[0].squeeze(axis=(-1)) / 255 # for images\n",
    "        self.labels = test_data[1]\n",
    "\n",
    "        plt.imshow(images[0])\n",
    "        plt.show()\n",
    "        print(labels[0])\n",
    "        \n",
    "        \n",
    "        for k, image in enumerate(images):\n",
    "            self.x = image[np.newaxis, :, :]\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            print(labels[k])\n",
    "            \n",
    "            preds = []\n",
    "            \n",
    "            for i in range(self.target_N):\n",
    "                try_count = 0\n",
    "                self.i = i\n",
    "                try:\n",
    "                    self.j = 0\n",
    "\n",
    "                    pred_dict[decoder[i]] = self.forward()\n",
    "                    preds.append(self.backward(pred_dict))\n",
    "\n",
    "                    j += 1\n",
    "                except(ValueError) as e:\n",
    "                    print(\"==========Numerical instability occured retrying calculations==========\")\n",
    "                    print(\"==========Calculations retried {} / 10 times==========\".format(try_count + 1))\n",
    "                    print(e)\n",
    "                    try_count += 1\n",
    "\n",
    "                    if try_count == 10:\n",
    "                        print(\"==========Major error occured rerun program==========\")\n",
    "                        return 1\n",
    "                sums_of_errors.append(self.cumulative_error)\n",
    "                self.cumulative_error = 0\n",
    "        print(np.argmin(preds), label[k])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "streaming-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 µs, sys: 0 ns, total: 40 µs\n",
      "Wall time: 43.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = Forward_and_backward(N, sorted_data, test_data, 3) # iterations should be low due to one shot training\n",
    "                                                                                                # or else gradients will average out to nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "guided-aggregate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(606, 28, 28)\n",
      "working on 0s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 0.7708117091911271\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  0\n",
      "Prediction for class based off of current =  0\n",
      "working on 0s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 0.4249740510293525\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  0\n",
      "Prediction for class based off of current =  0\n",
      "working on 0s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = -0.11224759454907751\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  0\n",
      "Prediction for class based off of current =  0\n",
      "(689, 28, 28)\n",
      "working on 1s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 0.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  1\n",
      "Prediction for class based off of current =  1\n",
      "working on 1s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 0.09629887232462542\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  1\n",
      "Prediction for class based off of current =  1\n",
      "working on 1s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = -0.43361888039369967\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  1\n",
      "Prediction for class based off of current =  1\n",
      "(600, 28, 28)\n",
      "working on 2s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 1.1879533286100878\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  2\n",
      "Prediction for class based off of current =  2\n",
      "working on 2s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 0.9255439943321053\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  2\n",
      "Prediction for class based off of current =  2\n",
      "working on 2s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 0.3771985722358364\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  2\n",
      "Prediction for class based off of current =  2\n",
      "(624, 28, 28)\n",
      "working on 3s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 0.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  3\n",
      "Prediction for class based off of current =  3\n",
      "working on 3s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 0.17484098785486024\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  3\n",
      "Prediction for class based off of current =  3\n",
      "working on 3s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = -0.35682214520858113\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  3\n",
      "Prediction for class based off of current =  3\n",
      "(636, 28, 28)\n",
      "working on 4s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 1.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  4\n",
      "Prediction for class based off of current =  4\n",
      "working on 4s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 0.9641915087133022\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  4\n",
      "Prediction for class based off of current =  4\n",
      "working on 4s\n",
      "iteration 3 / 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 0.41498725296411765\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  4\n",
      "Prediction for class based off of current =  4\n",
      "(524, 28, 28)\n",
      "working on 5s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 0.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  5\n",
      "Prediction for class based off of current =  5\n",
      "working on 5s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 0.3504401754668305\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  5\n",
      "Prediction for class based off of current =  5\n",
      "working on 5s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = -0.18512516176576566\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  5\n",
      "Prediction for class based off of current =  5\n",
      "(620, 28, 28)\n",
      "working on 6s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 1.4768144108896308\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  6\n",
      "Prediction for class based off of current =  6\n",
      "working on 6s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 1.272177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  6\n",
      "Prediction for class based off of current =  6\n",
      "working on 6s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 0.7161289087771667\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  6\n",
      "Prediction for class based off of current =  6\n",
      "(668, 28, 28)\n",
      "working on 7s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 0.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  7\n",
      "Prediction for class based off of current =  7\n",
      "working on 7s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 0.3072992174989486\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  7\n",
      "Prediction for class based off of current =  7\n",
      "working on 7s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = -0.22730743177880586\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  7\n",
      "Prediction for class based off of current =  7\n",
      "(562, 28, 28)\n",
      "working on 8s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 0.9511052240054396\n",
      "Total error of 9 = 1.7760548698735512\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  8\n",
      "working on 8s\n",
      "iteration 2 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 0.6413262688065275\n",
      "Total error of 9 = 2.1312658438482615\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  8\n",
      "working on 8s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 0.09929679616638243\n",
      "Total error of 9 = 2.0839043806516333\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  8\n",
      "(615, 28, 28)\n",
      "working on 9s\n",
      "iteration 1 / 3\n",
      "init W\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.770811709191127\n",
      "Total error of 1 = 1.4969157269371878\n",
      "Total error of 2 = 2.187953328610088\n",
      "Total error of 3 = 1.5623674898790503\n",
      "Total error of 4 = 2.2201595905944185\n",
      "Total error of 5 = 1.7087001462223588\n",
      "Total error of 6 = 2.476814410889631\n",
      "Total error of 7 = 1.6727493479157904\n",
      "Total error of 8 = 1.9511052240054396\n",
      "Total error of 9 = 0.7760548698735512\n",
      "Prediction for class based off of total =  9\n",
      "Prediction for class based off of current =  9\n",
      "working on 9s\n",
      "iteration 2 / 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.124974051029352\n",
      "Total error of 1 = 1.7962988723246254\n",
      "Total error of 2 = 2.625543994332105\n",
      "Total error of 3 = 1.8748409878548602\n",
      "Total error of 4 = 2.6641915087133023\n",
      "Total error of 5 = 2.0504401754668304\n",
      "Total error of 6 = 2.972177293067557\n",
      "Total error of 7 = 2.0072992174989484\n",
      "Total error of 8 = 2.3413262688065277\n",
      "Total error of 9 = 0.4312658438482613\n",
      "Prediction for class based off of total =  9\n",
      "Prediction for class based off of current =  9\n",
      "working on 9s\n",
      "iteration 3 / 3\n",
      "working on lie algebra 100 / 100\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 2.077752405450922\n",
      "Total error of 1 = 1.7563811196063002\n",
      "Total error of 2 = 2.567198572235836\n",
      "Total error of 3 = 1.8331778547914186\n",
      "Total error of 4 = 2.6049872529641176\n",
      "Total error of 5 = 2.004874838234234\n",
      "Total error of 6 = 2.906128908777167\n",
      "Total error of 7 = 1.9626925682211938\n",
      "Total error of 8 = 2.2892967961663824\n",
      "Total error of 9 = -0.10609561934836664\n",
      "Prediction for class based off of total =  9\n",
      "Prediction for class based off of current =  9\n",
      "CPU times: user 31min 19s, sys: 4min 24s, total: 35min 43s\n",
      "Wall time: 24min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained = train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-track",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  0\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  1\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  2\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  3\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  4\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  5\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  6\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  7\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  8\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  0\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  1\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  2\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  3\n",
      "\n",
      "probibility distiribution =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "Total error of 0 = 1.402862358081747\n",
      "Total error of 1 = 1.4095624158893585\n",
      "Total error of 2 = 1.5587391667873527\n",
      "Total error of 3 = 1.8406805300926823\n",
      "Total error of 4 = 1.725047553881494\n",
      "Total error of 5 = 2.002039235233232\n",
      "Total error of 6 = 1.625684698655422\n",
      "Total error of 7 = 1.3350620235994117\n",
      "Total error of 8 = 1.309833584377956\n",
      "Total error of 9 = 1.4240670543444673\n",
      "Prediction for class based off of total =  8\n",
      "Prediction for class based off of current =  4\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d491ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-bosnia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
