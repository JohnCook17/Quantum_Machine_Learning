{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sublime-filter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 1.17 s, total: 3.52 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gzip\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organized-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 125 ms, sys: 1.63 ms, total: 126 ms\n",
      "Wall time: 127 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Useful additional packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.version.version\n",
    "np.seterr(all=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 868 ms, sys: 72 ms, total: 940 ms\n",
      "Wall time: 887 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, execute\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.quantum_info import state_fidelity, OneQubitEulerDecomposer\n",
    "from qiskit import  Aer, transpile, IBMQ, assemble\n",
    "from qiskit.circuit.library import CHGate\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit.aqua.operators import PrimitiveOp, CircuitStateFn\n",
    "from qiskit.aqua.operators.primitive_ops import MatrixOp\n",
    "from qiskit.aqua.operators.converters import CircuitSampler\n",
    "from qiskit.aqua.operators.expectations import MatrixExpectation # factory or matirx?\n",
    "from qiskit.aqua.operators.list_ops import ComposedOp\n",
    "from qiskit.aqua.operators import ListOp\n",
    "from qiskit.aqua.components.initial_states import Zero\n",
    "import qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understood-machinery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 0 ns, total: 109 ms\n",
      "Wall time: 107 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from Lie_alge.Sophus.py.sophus import so2, so3\n",
    "from geomstats.geometry.special_orthogonal import SpecialOrthogonal\n",
    "from geomstats.learning.pca import TangentPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vulnerable-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__init__.discover_credentials:INFO:2021-05-04 09:28:22,415: Using credentials from qiskitrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65 ms, sys: 21.7 ms, total: 86.7 ms\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "provider = IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfied-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prescription-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 ms, sys: 628 µs, total: 2.44 ms\n",
      "Wall time: 2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.9/site-packages/qiskit/aqua/quantum_instance.py:135: DeprecationWarning: The class qiskit.aqua.QuantumInstance is deprecated. It was moved/refactored to qiskit.utils.QuantumInstance (pip install qiskit-terra). For more information see <https://github.com/Qiskit/qiskit-aqua/blob/master/README.md#migration-guide>\n",
      "  warn_class('aqua.QuantumInstance',\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print(Aer.backends())\n",
    "simulator = Aer.get_backend(\"statevector_simulator\")\n",
    "# simulator.set_option(method=)\n",
    "my_sampler = CircuitSampler(backend=simulator, attach_results=True, param_qobj=False)  # read up on this more\n",
    "my_expectation = MatrixExpectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desirable-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# EMNIST decoder\n",
    "\n",
    "decoder = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 ms, sys: 527 µs, total: 2.05 ms\n",
      "Wall time: 5.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "images_raw = gzip.open(\"data/MNIST/MNIST_GZ/train-images-idx3-ubyte.gz\", \"r\")\n",
    "labels_raw = gzip.open(\"data/MNIST/MNIST_GZ/train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "\n",
    "image_size = 28\n",
    "num_images = 4096 # how many images per batch\n",
    "\n",
    "images_raw.read(16) # reads the data type\n",
    "labels_raw.read(8) # reads the data type\n",
    "\n",
    "def get_data(images, labels):\n",
    "    buf_images = images.read(image_size * image_size * num_images)\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(num_images, image_size, image_size, 1)\n",
    "    \n",
    "    buf_labels = labels.read(num_images)\n",
    "    labels = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int32)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hired-pakistan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 106 ms, sys: 10.7 ms, total: 117 ms\n",
      "Wall time: 143 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print images\n",
    "data = get_data(images_raw, labels_raw)\n",
    "\n",
    "images = data[0]\n",
    "labels = data[1]\n",
    "\n",
    "\n",
    "\n",
    "sort_index = np.argsort(data[1], axis=0)\n",
    "\n",
    "sorted_images = data[0][sort_index]\n",
    "sorted_labels = data[1][sort_index]\n",
    "\n",
    "sorted_data = sorted_images, sorted_labels\n",
    "\n",
    "image = np.asarray(sorted_images[1]).T.squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(decoder[sorted_labels[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "posted-therapy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n",
      "CPU times: user 392 µs, sys: 0 ns, total: 392 µs\n",
      "Wall time: 264 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.set_printoptions(threshold=2 ** 10 + 1)\n",
    "print(sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intense-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_num_cls(data):\n",
    "    labels = np.array(data[1])\n",
    "    one_hot_labels = to_categorical(labels)\n",
    "    \n",
    "    return one_hot_labels.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aerial-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "CPU times: user 553 µs, sys: 188 µs, total: 741 µs\n",
      "Wall time: 443 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = get_num_cls(data)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inner-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    \"\"\"From https://towardsdatascience.com/how-to-implement-an-adam-optimizer-from-scratch-76e7b217f1cc\"\"\"\n",
    "    def __init__(self, num_of_keys=1, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.m_dw = {key: 0 for key in range(num_of_keys)}\n",
    "        self.v_dw = {key: 0 for key in range(num_of_keys)}\n",
    "        self.m_db, self.v_db = 0, 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "    def update(self, key, t, w, b, dw, db):\n",
    "        ## dw, db are from current minibatch\n",
    "        ## momentum beta 1\n",
    "        # *** weights *** #\n",
    "        self.m_dw[key] = self.beta1*self.m_dw[key] + (1-self.beta1)*dw\n",
    "        # *** biases *** #\n",
    "        self.m_db = self.beta1*self.m_db + (1-self.beta1)*db\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** weights *** #\n",
    "        self.v_dw[key] = self.beta2*self.v_dw[key] + (1-self.beta2)*(dw**2)\n",
    "        # *** biases *** #\n",
    "        self.v_db = self.beta2*self.v_db + (1-self.beta2)*(db)\n",
    "\n",
    "        ## bias correction\n",
    "        m_dw_corr = self.m_dw[key]/(1-self.beta1**t + self.epsilon)\n",
    "        m_db_corr = self.m_db/(1-self.beta1**t + self.epsilon)\n",
    "        v_dw_corr = self.v_dw[key]/(1-self.beta2**t + self.epsilon)\n",
    "        v_db_corr = self.v_db/(1-self.beta2**t + self.epsilon)\n",
    "\n",
    "        ## update weights and biases\n",
    "        w = w + self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon)) # changed this to a - from a + for the first two terms\n",
    "        b = b + self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon)) # changed this to a - from a + for the first two terms\n",
    "        return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "least-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "class Forward_and_backward:\n",
    "    \"\"\"see:\n",
    "        https://arxiv.org/pdf/1908.08385.pdf\n",
    "        equations 1 and 2\n",
    "        also see:\n",
    "        https://qiskit.org/documentation/stubs/qiskit.circuit.library.CHGate.html\n",
    "    \"\"\"\n",
    "    def __init__(self, N, data, num_of_it):\n",
    "        \"\"\"\"\"\"\n",
    "        self.num_of_it = num_of_it\n",
    "        self.target_N = N\n",
    "        self.N = self.target_N - 1\n",
    "        self.data = data\n",
    "        self.alpha = np.arange(start=1, stop=self.target_N ** 2 + 1, dtype=np.complex_) # kind of like biases\n",
    "        # self.K = 1\n",
    "        # self.P = []\n",
    "        # self.P_idx = 0\n",
    "        self.total_error = {}\n",
    "        self.Ek = {}\n",
    "        self.set_lie_alge = True\n",
    "    \n",
    "    def H(self):\n",
    "        \"\"\"\"\"\"\n",
    "        euler = self.A() * self.SU_of_Nm1(self.target_N) * np.exp(1j * np.sum(self.lie_alge) * np.sum(self.alpha))\n",
    "        \n",
    "        # print(\"A = \", self.A())\n",
    "        # print(\"SU N - 1 = \", self.SU_of_Nm1(self.target_N))\n",
    "        # print(\"NP.exp = \", np.exp(1j * np.sum(self.lie_alge) * np.sum(self.alpha)))\n",
    "        # print(\"lie\", np.sum(self.lie_alge))\n",
    "        # print(\"alpha\", np.sum(self.alpha))\n",
    "        \n",
    "        # print(euler)\n",
    "        euler = OneQubitEulerDecomposer(\"ZYZ\").angles(euler)\n",
    "        \n",
    "        # print(euler)\n",
    "        \n",
    "        def map_circuit(k, qc_k):\n",
    "            \"\"\"\"\"\"\n",
    "            for i in range(self.target_N):\n",
    "                try:\n",
    "                    qc_k.cx(k, i) @ (np.asarray(euler)[np.newaxis]).T\n",
    "                except:\n",
    "                    #print(qc_k)\n",
    "                    continue\n",
    "\n",
    "        qr = QuantumRegister(self.target_N, \"qreg\")\n",
    "        qc_k = QuantumCircuit(qr, name=\"qc_k\")\n",
    "        # print(type(qc_k))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for k in range(1, self.target_N + 1):\n",
    "            qc_k.initialize([np.sqrt(1/2), np.sqrt(1/2)], qubits=k - 1) # might be 1, 0\n",
    "        \n",
    "        for k in range(self.target_N):  # has to be seperate loop to have h gate be first\n",
    "            map_circuit(k, qc_k)\n",
    "            # END ROTATIONS\n",
    "            # qc_k.h(k)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # self.cr_k = ClassicalRegister(self.target_N, name=\"cr_k\")\n",
    "        # self.qc_k.add_register(self.cr_k)\n",
    "        op = PrimitiveOp(qc_k)\n",
    "        # print(op.num_qubits)\n",
    "\n",
    "        h = []\n",
    "        for i in range(self.x.shape[2]):\n",
    "            # row = []\n",
    "            # for k in range(self.target_N ):  # REMOVE THIS?\n",
    "                # row.append(op)\n",
    "            h.append(op) # was row\n",
    "            # print(\"term1 = \", term1)\n",
    "\n",
    "            # h.append(row)\n",
    "            # row.append(h)\n",
    "            # print(h[i])\n",
    "            \n",
    "        vec_0 = np.zeros(shape=(self.target_N, self.target_N), dtype=np.complex_)\n",
    "        vec_0[0, 0] = 1\n",
    "        vec_0 = np.asmatrix(vec_0).H\n",
    "        vec_0 = np.asarray(vec_0) # might help it go faster?\n",
    "            \n",
    "        h = np.asarray(h, dtype=object)[:np.newaxis]\n",
    "        # print(\"h shape = \", h.shape)\n",
    "        H_op = np.asarray(h / np.sqrt(self.target_N, dtype=np.complex_), dtype=object) \n",
    "\n",
    "        # print(H_op.shape)\n",
    "        # print(vec_0.shape)\n",
    "        \n",
    "        # H_op= H_op @ vec_0\n",
    "        \n",
    "        # print(\"h_op =\", H_op.shape)\n",
    "        \n",
    "        return H_op\n",
    "        \n",
    "    def quNit(self, SU_of_N):\n",
    "        # qr = QuantumRegister(self.target_N, 'a')\n",
    "        \n",
    "        S3 =np.zeros(shape=(self.target_N, self.target_N), dtype=np.complex_)\n",
    "        np.fill_diagonal(S3, -(self.target_N - 1) / 2)\n",
    "        # print(self.x.shape)\n",
    "        # print(self.W[self.i].shape)\n",
    "        sum_of_weights = np.sum(np.asarray([w @ x for w, x in zip(self.W[self.i], self.x)]), axis=0)\n",
    "        # print(sum_of_weights)\n",
    "        Z = np.exp((1j) * S3) \n",
    "        \n",
    "        # print(\"weights = \", sum_of_weights.shape)\n",
    "\n",
    "        self.lie_alge = self.lie_algebra(SU_of_N)\n",
    "        \n",
    "        qn = Z @ (sum_of_weights @ self.H()).T\n",
    "        # print(\"QN shape = \", qn.shape)\n",
    "        return qn # init state should be 0\n",
    "\n",
    " ##################################################   \n",
    "\n",
    "    def A(self):\n",
    "        a = []\n",
    "        epsilon = 1e-08\n",
    "        # print(lie_alge.shape)\n",
    "        \n",
    "        for k in range(2, self.target_N + 1):\n",
    "            \n",
    "            val = np.exp(1j * self.lie_alge[3] * self.alpha[2 * k - 3] * np.exp(1j * self.lie_alge[((k - 1) ** 2 + 1)] * self.alpha[2 * (k - 1)]))\n",
    "            \n",
    "            a.append(val + epsilon) \n",
    "        \n",
    "        \n",
    "        # print(\"A.shape = \", a.shape)\n",
    "        \n",
    "        return np.prod(a) \n",
    "\n",
    "    def SU_of_Nm1(self, n):\n",
    "        n -= 1\n",
    "        son = SpecialOrthogonal(n=n, point_type='matrix')\n",
    "        # print(son)\n",
    "        metric = son.bi_invariant_metric\n",
    "\n",
    "        data = son.random_uniform(n_samples=(self.target_N))\n",
    "\n",
    "        tpca = TangentPCA(metric=metric, n_components=(self.target_N))  ## SELF.TARGET_N?\n",
    "        tpca = tpca.fit(data)\n",
    "        tangent_projected_data = tpca.transform(data)\n",
    "        return tangent_projected_data\n",
    "    \n",
    "    def SU_of_N(self, n):\n",
    "        \"\"\"\"\"\"\n",
    "        son = SpecialOrthogonal(n=n, point_type='matrix')\n",
    "        # print(son)\n",
    "        metric = son.bi_invariant_metric\n",
    "\n",
    "        data = son.random_uniform(n_samples=(self.target_N))\n",
    "\n",
    "        tpca = TangentPCA(metric=metric, n_components=(self.target_N))  ## SELF.TARGET_N?\n",
    "        tpca = tpca.fit(data)\n",
    "        tangent_projected_data = tpca.transform(data)\n",
    "        return tangent_projected_data\n",
    "\n",
    "    def lie_algebra(self, SU_N):\n",
    "        \"\"\"\"\"\"\n",
    "        \n",
    "        if self.set_lie_alge == True:\n",
    "            self.set_lie_alge = False\n",
    "            i = 0\n",
    "            epsilon = 1e-10\n",
    "            lie_algebras = []\n",
    "            while i < self.target_N ** 2:\n",
    "                print(\"working on lie algebra {} / {}\".format(i, self.target_N ** 2))\n",
    "                delta = epsilon * np.random.uniform(low=-1, high=1, size=(1))\n",
    "                mat = np.full((self.target_N, self.target_N), delta)\n",
    "                np.fill_diagonal(mat, 0)\n",
    "                if not np.linalg.det(mat):\n",
    "                    continue\n",
    "                else:\n",
    "                    i += 1\n",
    "                    lie = mat \n",
    "                    lie_algebras.append(lie)\n",
    "                    # print(lie)\n",
    "\n",
    "            return np.asarray(lie_algebras, dtype= complex)\n",
    "\n",
    "        else:\n",
    "            return self.lie_alge\n",
    "    ############################################\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        \"\"\"\"\"\"\n",
    "        # init values for forward\n",
    "        SU_N = self.SU_of_N(self.target_N)\n",
    "        ket_x = self.quNit(SU_N)\n",
    "        \n",
    "        \n",
    "        # weighted ket_x\n",
    "        \n",
    "        # print(\"before su(n)\", ket_x.shape)\n",
    "        # print(SU_N.shape)\n",
    "        \n",
    "        ket_x = SU_N @ ket_x\n",
    "        \n",
    "        # print(\"########KET X##########\", ket_x)\n",
    "\n",
    "        ket_x_list = []\n",
    "        \n",
    "        # print(\"after\", ket_x.shape)\n",
    "        # print(ket_x)\n",
    "\n",
    "        for k, op in enumerate(ket_x):\n",
    "            cr = ClassicalRegister(self.target_N, \"creg{}\".format(k))\n",
    "            qc = my_expectation.convert(op)\n",
    "            qc = qc.to_circuit()\n",
    "            # qc.add_register(qr)\n",
    "            qc.add_register(cr)\n",
    "            qc.measure_all([val for val in range(self.target_N - 1)])\n",
    "            qobj = assemble(qc, shots= 2 ** self.target_N)\n",
    "            job = simulator.run(qobj)\n",
    "            # data = job.result().data(self.qc)\n",
    "            vec = job.result().get_statevector(qc, decimals=10)\n",
    "            # print(vec)\n",
    "            ket_x_list.append(vec)\n",
    "        \n",
    "        ket_x = np.asarray(ket_x_list)\n",
    "        \n",
    "        # print(ket_x)\n",
    "        \n",
    "        # print(ket_x)\n",
    "        # print(ket_x.shape)\n",
    "        \n",
    "        \n",
    "        def Purity(N, ket_x):\n",
    "            \"\"\"\"\"\"\n",
    "            bra_x = np.asmatrix(ket_x).H\n",
    "            \n",
    "            return ((ket_x @ bra_x) / N) ** 2\n",
    "            \n",
    "        Pa = Purity(self.target_N, ket_x)\n",
    "        # print(Pa)\n",
    "        Pa = np.diag(Pa)\n",
    "        print(Pa.shape)\n",
    "        Pb = np.argmax(Pa)\n",
    "        print(\"prediction = \", Pb)\n",
    "        print(\"probs = \", Pa.real)\n",
    "\n",
    "        return Pb, ket_x\n",
    "\n",
    "    def backward(self, pred_dict):\n",
    "        \"\"\"\"\"\"\n",
    "        SU_N = self.SU_of_N(self.target_N)\n",
    "        qc = self.H()\n",
    "        Mk = self.target_N # * self.target_N\n",
    "        \n",
    "        ket_x = pred_dict[decoder[self.i]][1]\n",
    "        \n",
    "        # print(ket_x.shape)\n",
    "        \n",
    "        Pk = np.sum((np.matrix(ket_x) @ np.matrix(ket_x).H)  / Mk)\n",
    "\n",
    "        print(Pk.shape)\n",
    "        print(SU_N.shape)\n",
    "        \n",
    "        Pk = np.asarray(np.asmatrix(SU_N) * Pk * np.asmatrix(SU_N).H, dtype=np.complex_)\n",
    "\n",
    "        # print(qc.shape)\n",
    "        \n",
    "        # print(\"Pk after sun = \", Pk.shape)\n",
    "\n",
    "        Pk = np.diagonal(Pk)\n",
    "        \n",
    "        # print(Pk)\n",
    "        \n",
    "        # back prop probs\n",
    "        for i, value in enumerate(Pk):\n",
    "            print(\"chance of {} = {}\".format(i, (value.real) / Mk))\n",
    "            \n",
    "        \n",
    "        self.Ek[self.i] = 1 - Pk\n",
    "\n",
    "    def cost(self):\n",
    "        Mk = self.target_N * self.target_N\n",
    "        \n",
    "        e = self.Ek[self.i]\n",
    "        e /= Mk\n",
    "\n",
    "        print(\"error shape =\", e.shape)\n",
    "        \n",
    "        self.total_error[self.i] = e\n",
    "    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\"\"\"\n",
    "        adam = AdamOptim(num_of_keys=self.target_N)\n",
    "        pred_dict = {}\n",
    "        init_W = True\n",
    "        self.W = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(self.target_N):\n",
    "            for j in range(self.num_of_it):\n",
    "                self.i = i\n",
    "                print(\"working on {}s\".format(decoder[i]))\n",
    "                sorted_images = self.data[0]\n",
    "                sorted_labels = self.data[1]\n",
    "                # print(sorted_labels.shape)\n",
    "                y = sorted_labels[sorted_labels == i]\n",
    "                # print(y)\n",
    "                self.x = sorted_images[sorted_labels == i]\n",
    "\n",
    "                try:\n",
    "                    # print(self.x.shape)\n",
    "                    self.x = self.x.squeeze(axis=(0, -1))\n",
    "                    # print(self.x.shape)\n",
    "                except(ValueError):\n",
    "                    # print(self.x.shape)\n",
    "                    self.x = self.x.squeeze(axis=-1)\n",
    "                    # print(self.x.shape)\n",
    "\n",
    "                \"\"\"image = self.x[0]\n",
    "                plt.imshow(image)\n",
    "                plt.show()\"\"\"\n",
    "\n",
    "                if init_W:\n",
    "                    print(\"init W\")\n",
    "                    self.W[self.i] = np.random.random(size=(self.x.shape[0], self.target_N, self.x.shape[2])) # learnable similar to weights\n",
    "\n",
    "                pred_dict[decoder[i]] = self.forward()\n",
    "                self.backward(pred_dict)\n",
    "                self.cost()\n",
    "\n",
    "                print(self.total_error[self.i])\n",
    "                \n",
    "                dw = (np.asarray([w @ w.T for w in self.W[self.i]], dtype=np.complex_) @ self.total_error[self.i])[:, :, np.newaxis]\n",
    "                db = self.alpha  @ self.alpha.T * np.sum(self.total_error[self.i])\n",
    "\n",
    "                self.W[self.i], self.alpha = adam.update(key=i, t=j, w=self.W[self.i], b=self.alpha, dw=dw, db=db)\n",
    "                print(\"error = \", self.total_error[self.i].real)\n",
    "\n",
    "                init_W = False\n",
    "        init_W = True\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "streaming-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "train = Forward_and_backward(N, sorted_data, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 0s\n",
      "init W\n",
      "working on lie algebra 0 / 100\n",
      "working on lie algebra 1 / 100\n",
      "working on lie algebra 2 / 100\n",
      "working on lie algebra 3 / 100\n",
      "working on lie algebra 4 / 100\n",
      "working on lie algebra 5 / 100\n",
      "working on lie algebra 6 / 100\n",
      "working on lie algebra 7 / 100\n",
      "working on lie algebra 8 / 100\n",
      "working on lie algebra 9 / 100\n",
      "working on lie algebra 10 / 100\n",
      "working on lie algebra 11 / 100\n",
      "working on lie algebra 12 / 100\n",
      "working on lie algebra 13 / 100\n",
      "working on lie algebra 14 / 100\n",
      "working on lie algebra 15 / 100\n",
      "working on lie algebra 16 / 100\n",
      "working on lie algebra 17 / 100\n",
      "working on lie algebra 18 / 100\n",
      "working on lie algebra 19 / 100\n",
      "working on lie algebra 20 / 100\n",
      "working on lie algebra 21 / 100\n",
      "working on lie algebra 22 / 100\n",
      "working on lie algebra 23 / 100\n",
      "working on lie algebra 24 / 100\n",
      "working on lie algebra 25 / 100\n",
      "working on lie algebra 26 / 100\n",
      "working on lie algebra 27 / 100\n",
      "working on lie algebra 28 / 100\n",
      "working on lie algebra 29 / 100\n",
      "working on lie algebra 30 / 100\n",
      "working on lie algebra 31 / 100\n",
      "working on lie algebra 32 / 100\n",
      "working on lie algebra 33 / 100\n",
      "working on lie algebra 34 / 100\n",
      "working on lie algebra 35 / 100\n",
      "working on lie algebra 36 / 100\n",
      "working on lie algebra 37 / 100\n",
      "working on lie algebra 38 / 100\n",
      "working on lie algebra 39 / 100\n",
      "working on lie algebra 40 / 100\n",
      "working on lie algebra 41 / 100\n",
      "working on lie algebra 42 / 100\n",
      "working on lie algebra 43 / 100\n",
      "working on lie algebra 44 / 100\n",
      "working on lie algebra 45 / 100\n",
      "working on lie algebra 46 / 100\n",
      "working on lie algebra 47 / 100\n",
      "working on lie algebra 48 / 100\n",
      "working on lie algebra 49 / 100\n",
      "working on lie algebra 50 / 100\n",
      "working on lie algebra 51 / 100\n",
      "working on lie algebra 52 / 100\n",
      "working on lie algebra 53 / 100\n",
      "working on lie algebra 54 / 100\n",
      "working on lie algebra 55 / 100\n",
      "working on lie algebra 56 / 100\n",
      "working on lie algebra 57 / 100\n",
      "working on lie algebra 58 / 100\n",
      "working on lie algebra 59 / 100\n",
      "working on lie algebra 60 / 100\n",
      "working on lie algebra 61 / 100\n",
      "working on lie algebra 62 / 100\n",
      "working on lie algebra 63 / 100\n",
      "working on lie algebra 64 / 100\n",
      "working on lie algebra 65 / 100\n",
      "working on lie algebra 66 / 100\n",
      "working on lie algebra 67 / 100\n",
      "working on lie algebra 68 / 100\n",
      "working on lie algebra 69 / 100\n",
      "working on lie algebra 70 / 100\n",
      "working on lie algebra 71 / 100\n",
      "working on lie algebra 72 / 100\n",
      "working on lie algebra 73 / 100\n",
      "working on lie algebra 74 / 100\n",
      "working on lie algebra 75 / 100\n",
      "working on lie algebra 76 / 100\n",
      "working on lie algebra 77 / 100\n",
      "working on lie algebra 78 / 100\n",
      "working on lie algebra 79 / 100\n",
      "working on lie algebra 80 / 100\n",
      "working on lie algebra 81 / 100\n",
      "working on lie algebra 82 / 100\n",
      "working on lie algebra 83 / 100\n",
      "working on lie algebra 84 / 100\n",
      "working on lie algebra 85 / 100\n",
      "working on lie algebra 86 / 100\n",
      "working on lie algebra 87 / 100\n",
      "working on lie algebra 88 / 100\n",
      "working on lie algebra 89 / 100\n",
      "working on lie algebra 90 / 100\n",
      "working on lie algebra 91 / 100\n",
      "working on lie algebra 92 / 100\n",
      "working on lie algebra 93 / 100\n",
      "working on lie algebra 94 / 100\n",
      "working on lie algebra 95 / 100\n",
      "working on lie algebra 96 / 100\n",
      "working on lie algebra 97 / 100\n",
      "working on lie algebra 98 / 100\n",
      "working on lie algebra 99 / 100\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-track",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-bosnia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-adobe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304efcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55acf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
